# VLSI-AI-Project-From-Wrire-Length-Predictor-Model-to-Public-Web-App
This project started by using Linear Regression to predict VLSI chip metrics like wire length. It was then enhanced by integrating a Large Language Model (LLM) to analyze error logs. The final web app acts as a powerful AI assistant, providing simplified explanations and fixes for complex VLSI issues.

1] OpenLane Wire Length Predictor üí°
This project introduces a data-driven approach to optimize digital chip design using AI. By combining the OpenLane automated design flow with a simple Linear Regression model, we can predict a chip's final wire length based on key physical design parameters. This allows engineers to quickly explore the design space without running a full, time-consuming EDA flow for every single option.

Features ‚ú®
Predictive AI Model: Uses a trained machine learning model to estimate wire length.

Data-Driven: The model is trained on real-world design metrics generated by the OpenLane flow.

Multivariable Analysis: Accounts for the impact of both Core Utilization (FP_CORE_UTIL) and Aspect Ratio (FP_ASPECT_RATIO) on the final design.

Fast Optimization: Provides near-instantaneous predictions, saving hours of design time.

Getting Started üöÄ
To use this tool, you need a Python environment with the necessary libraries.

Prerequisites
Python 3.x

pip (Python package installer)

Installation
Clone this repository to your local machine:

Bash

git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name
Install the required Python libraries. A requirements.txt file is included for your convenience.

Bash

pip install -r requirements.txt
How to Use It ‚öôÔ∏è
Prepare Your Data: Run the OpenLane flow multiple times with different values for FP_CORE_UTIL and FP_ASPECT_RATIO in your config.json file. Manually compile the metrics.csv output from each run into a single master_metrics.csv file.

Train the Model: Run the main Python script to train the model on your dataset.

Bash

python3 train_model.py
The script will use the data in master_metrics.csv to learn the relationships between your inputs and the output.

Make a Prediction: The script is set to predict wire length for a utilization of 75% and an aspect ratio of 1.2 by default. You can easily modify the script to predict for any new values you want to explore.

Project Methodology üß†
This project was built following a four-phase methodology:

Phase 1: Initial Data Collection: Executed a baseline OpenLane run to understand the design flow and generate a single data point.

Phase 2: Single-Variable AI: Trained a simple model on a single variable (FP_CORE_UTIL) to establish a foundational understanding of AI in this context.

Phase 3: Multivariable Dataset Creation: Systematically collected a diverse dataset by varying both FP_CORE_UTIL and FP_ASPECT_RATIO, navigating challenges and flow failures to create a robust dataset.

Phase 4: Final Model Training: Trained a comprehensive multivariable linear regression model on the complete dataset, yielding the final predictive tool.

Learned Insights üìà
After training the model on the collected data, it produced the following key coefficients. These numbers represent the learned relationship between each parameter and wire length.

Learned coefficients: [ 22.57 -394.83 ]

Interpretation:

A 1% increase in core utilization leads to an approximate 22.57 ¬µm increase in total wire length.

A 1-unit increase in aspect ratio leads to an approximate 394.83 ¬µm decrease in total wire length.

Predicted Wire Length (75% util, 1.2 AR): 7235.59 ¬µm

2] The Large Language Model (LLM)
The LLM is the "brain" of your web application. It is a sophisticated AI model that has been trained on a massive amount of text and code. It doesn't just recognize patterns; it understands context, follows instructions, and generates human-like responses.

In your project, the LLM's role is not to predict numerical data like wire length (that was your linear regression model), but to perform complex text-based analysis. When you send it a VLSI error log, you are essentially asking it to do the following:

Understand the Prompt: It receives your input, which includes the raw text of the error log, and your specific instructions (the prompt) to "act as a world-class VLSI expert."

Analyze the Log: The LLM's vast training data allows it to identify common error codes (like GPL-0302 or GRT-0010) and understand what they mean in the context of a VLSI design flow.

Synthesize a Response: It then uses this understanding to formulate a clear, simple explanation and a suggested fix, just like an experienced engineer would. It translates technical jargon into actionable advice.

Essentially, you are not building the LLM; you are leveraging it as a service. You have created a pipeline to send it a specific problem and receive an intelligent, helpful solution in return.

3] The Website
The website you built is the user interface and the communication channel for your LLM. It's what makes your powerful backend tool accessible and easy to use for anyone, even those who aren't familiar with command-line tools.

index.html file is a single, self-contained application that performs three main functions:

User Input: It provides a clean, responsive front end with a text area where a user can paste their error logs. The design, using Tailwind CSS, makes it look professional and intuitive.

API Integration: The JavaScript code within the file is the key. It waits for the user to click the "Analyze Log" button, then takes the text from the input box, formats it into a prompt, and sends it as a request to the Gemini API. This is the bridge that connects your front end to the LLM.

Output Display: After the API returns a response, the JavaScript code processes the data and dynamically updates a section of the web page to show the analysis. It also handles user experience elements like the loading indicator and displaying error messages.

In summary, the website is the simple, powerful interface that allows you to provide a complex AI service without the user ever having to worry about the underlying technical details.

License and Contact üìß
This project is open-source. Please feel free to use, modify, and distribute it.

Author: Ashray Datta Pranesh Anegondi

License: [e.g., Apache 2.0 or MIT License]
